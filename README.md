# ğŸ¤– Ultron Web Scraper â€” Reddit Technostress Intelligence

Ultron is a powerful, modular Python scraper that gathers high-quality Reddit posts related to **technostress**, **digital burnout**, and **technology-induced stress**. It uses both Redditâ€™s official live API and the Pushshift archive API to pull real-time and historical data, then applies smart filtering, logs all actions, and stores results in a clean, structured CSV â€” ready for analysis or reporting.

---

## ğŸš€ Features

- ğŸ”— Fetches posts from both **Reddit API** and **Pushshift API**
- ğŸ” Uses multiple related **keywords** (e.g., "technostress", "burnout")
- ğŸŒ Detects and keeps **English-only** posts
- ğŸ§¹ Filters out:
  - Posts with â€œstudyâ€ or â€œinterviewâ€ in title or text
  - Posts with less than 150 characters
  - Posts with low interaction (score < 5, comments < 3)
- ğŸ“Š Tracks all activity in `activity_log.csv`
- âš ï¸ Logs skipped posts and reasons in `error_log.csv`
- ğŸ“ Exports clean results to `technostress_posts.csv`
- ğŸ““ Outputs debug logs to `scraper.log`

---

## ğŸ“ Project Structure

```plaintext
ultron-web-scrapper/
â”œâ”€â”€ config.py              # Stores Reddit API credentials
â”œâ”€â”€ fetch_reddit.py        # Pulls posts using Reddit's official PRAW API
â”œâ”€â”€ fetch_pushshift.py     # Pulls historical posts using Pushshift API
â”œâ”€â”€ logger.py              # Sets up logger for console and file output
â”œâ”€â”€ save_data.py           # Filters, cleans, saves valid posts to CSV
â”œâ”€â”€ tracker.py             # Logs all actions to activity_log.csv
â”œâ”€â”€ run_scraper.py         # Orchestrates scraping, filtering, saving
â”œâ”€â”€ scraper.log            # Debug and execution logs
â”œâ”€â”€ error_log.csv          # Skipped posts with reasons
â”œâ”€â”€ activity_log.csv       # Tracked user/system actions
â”œâ”€â”€ technostress_posts.csv # Final clean dataset
â”œâ”€â”€ requirements.txt       # All dependencies
â””â”€â”€ README.md              # This documentation
